replicaCount: 1

image:
  repository: quay.io/ecosystem-appeng/llamastack-dist-ui
  pullPolicy: IfNotPresent
  tag: 0.2.6

service:
  type: ClusterIP
  port: 8501

serviceAccount:
  create: false

livenessProbe:
  httpGet:
    path: /
    port: http

readinessProbe:
  httpGet:
    path: /
    port: http

env:
  - name: LLAMA_STACK_ENDPOINT
    value: 'http://llamastack:8321'

volumes:
  - emptyDir: {}
    name: dot-streamlit

volumeMounts:
  - mountPath: /.streamlit
    name: dot-streamlit

# Common model values for llm-service and llama-stack
# See format in https://github.com/RHEcosystemAppEng/ai-architecture-charts/blob/main/helm/llm-service/values.yaml
# For e.g., to add a new model add the following block and it will append to the list of models defined in the llm-service

# global:
#   models:
#     granite-vision-3-2-2b:
#     id: ibm-granite/granite-vision-3.2-2b
#     enabled: true
#     resources:
#       limits:
#         nvidia.com/gpu: "1"
#     tolerations:
#     - key: "nvidia.com/gpu"
#       operator: Exists
#       effect: NoSchedule
#     args:
#     - --tensor-parallel-size
#     - "1"
#     - --max-model-len
#     - "6144"
#     - --enable-auto-tool-choice
#     - --tool-call-parser
#     - granite


global:
  models: {}

pgvector:
  secret:
    user: postgres
    password: rag_password
    dbname: rag_blueprint
    host: pgvector
    port: "5432"

minio:
  secret:
    user: minio_rag_user
    password: minio_rag_password
    host: minio
    port: "9000"
  
    # Upload sample files to the minio bucket 
  sampleFileUpload:
    enabled: true
    bucket: documents
    urls: 
    - https://raw.githubusercontent.com/rh-ai-kickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_Grand_Invention.pdf
    - https://raw.githubusercontent.com/rh-ai-kickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_and_the_Town_of_Tumble_Town.pdf
    - https://raw.githubusercontent.com/rh-ai-kickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_and_the_Town_of_Whispering_Willows.pdf


llama-stack:
  mcp-servers: {}
    #  mcp-weather:
    #   uri: http://rag-mcp-weather:8000/sse


ingestion-pipeline:
  # options are [S3, URL]
  source: S3
  # embedding model to use for creating embeddings
  embedding_model: all-MiniLM-L6-v2
  # name of the vector db with version, pipeline will be created with pipeline_red_hat_openshift
  name: "zippity-zoo-vector-db"
  # version of the knowledgebase
  version: "1.0"

  S3:
    access_key_id: minio_rag_user
    secret_access_key: minio_rag_password
    bucket_name: documents
    endpoint_url: http://minio:9000
    region: us-east-1
